{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taaltheorie en Taalverwerking · 2019 · Assignment 5\n",
    "\n",
    "NLTK has a interface for working with WordNet in more detail than is possible with the web interface alone. In this assignment, we will explore that interface further. \n",
    "\n",
    "As you are becoming more comfortable with NLTK, this assignment will involve some searching through the documentation yourself in order to find the best functions or methods for your needs. Specifically, you will want to look at:\n",
    "\n",
    "  * *Natural Language Processing with Python* (The NLTK Book), Chapter 2, Section 5 (http://www.nltk.org/book/ch02.html)\n",
    "  * The `wordnet` module documentation (http://www.nltk.org/api/nltk.corpus.reader.html#module-nltk.corpus.reader.wordnet)\n",
    "  * The WordNet HOWTO for NLTK (http://www.nltk.org/howto/wordnet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILL THIS IN FOR YOUR GROUP, also name your file as: tttv-w19-<group>-<name1>-<name2>.ipynb\n",
    "\n",
    "# Group        :\n",
    "# Name - UvaID :\n",
    "# Name - UvaID :\n",
    "# Date         :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the WordNet interface\n",
    "\n",
    "The first time that you use WordNet, you will need to download it. You may comment that line out after you have WordNet working on your machine (but it does no harm to leave it there).\n",
    "\n",
    "You will also need the `math` module for this assignment, and so let's load that now, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using WordNet\n",
    "\n",
    "The starting point of most WordNet queries involves pulling lists of synsets for particular words. NLTK allows these queries to be restricted to specific parts of speech: `wn.NOUN`, `wn.VERB`, or `wn.ADJ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wn.synsets('bank')\n",
    "\n",
    "# [Synset('bank.n.01'),\n",
    "#  Synset('depository_financial_institution.n.01'),\n",
    "#  Synset('bank.n.03'),\n",
    "#  Synset('bank.n.04'),\n",
    "#  Synset('bank.n.05'),\n",
    "#  Synset('bank.n.06'),\n",
    "#  Synset('bank.n.07'),\n",
    "#  Synset('savings_bank.n.02'),\n",
    "#  Synset('bank.n.09'),\n",
    "#  Synset('bank.n.10'),\n",
    "#  Synset('bank.v.01'),\n",
    "#  Synset('bank.v.02'),\n",
    "#  Synset('bank.v.03'),\n",
    "#  Synset('bank.v.04'),\n",
    "#  Synset('bank.v.05'),\n",
    "#  Synset('deposit.v.02'),\n",
    "#  Synset('bank.v.07'),\n",
    "#  Synset('trust.v.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wn.synsets('bank', pos = wn.NOUN)\n",
    "\n",
    "# [Synset('bank.n.01'),\n",
    "#  Synset('depository_financial_institution.n.01'),\n",
    "#  Synset('bank.n.03'),\n",
    "#  Synset('bank.n.04'),\n",
    "#  Synset('bank.n.05'),\n",
    "#  Synset('bank.n.06'),\n",
    "#  Synset('bank.n.07'),\n",
    "#  Synset('savings_bank.n.02'),\n",
    "#  Synset('bank.n.09'),\n",
    "#  Synset('bank.n.10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Word similarity based on WordNet path length  (6 pts)\n",
    "\n",
    "Although NLTK provides `path_similarity()`, a function (and a method) for computing path-length similarity in WordNet, its definition is different than the definitions of path-length similarity in our textbook. In particular, NLTK only defines similarity between synsets, not whole words, and it normalises the similarity measure to fall between zero and one. \n",
    "\n",
    "Write a function `textbook_similarity()` that computes the similarity between two words, represented as Python strings, using the definitions of Equations 20.19 and 20.20 (2nd edition) or Equations 17.21 and 17.33 (3rd edition) in your textbook. In other words, return the maximum similarity across all pairs of senses of the two words, where similarity is defined to be `-log(shortest_path_length)`. Your function should include an argument to restrict the search to a specific part of speech. \n",
    "\n",
    "**N.B.:** Your function will require special treatment if the two words are the same (or part of the same synset), in which case the similarity should be `inf`, or if there is no path at all between the two words, in which case the similarity should be `-inf`. You may want to write a helper function to make this conversion for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textbook_similarity(word1, word2, pos):\n",
    "    #--> Replace the fake return statement with your implementation.\n",
    "    return 0.0\n",
    "\n",
    "print(textbook_similarity('port', 'port', wn.NOUN))  # Should be inf\n",
    "print(textbook_similarity('port', 'bank', wn.NOUN))  # Should be -1.61\n",
    "print(textbook_similarity('port', 'bank', wn.VERB))  # Should be -1.39\n",
    "print(textbook_similarity('port', 'drink', wn.VERB)) # Should be 0.00\n",
    "print(textbook_similarity('port', 'couch', wn.VERB)) # Should be -inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: The Lesk family\n",
    "\n",
    "#### 2.1 Simplified Lesk (4 pts)\n",
    "\n",
    "Implement the *simplified* Lesk algorithm to disambiguate words in the context of single sentences. Implement the algorithm as a function that accepts a word and its context (the sentence). Your function should return an object of the NLTK WordNet `Synset` class.\n",
    "\n",
    "**Hint:** Use the pseudo-code in your textbook as a model. The NLTK documentation will help you extract glosses (definitions) and examples. You may need to experiment with the interface before writing your function, so that you understand exactly how NLTK returns information from WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    'a', 'able', 'about', 'across', 'after', 'all', 'almost', 'also', \n",
    "    'am', 'among', 'an', 'and', 'any', 'are', 'as', 'at', \n",
    "    'be', 'because', 'been', 'but', 'by', 'can', 'cannot', 'could', \n",
    "    'dear', 'did', 'do', 'does', 'either', 'else', 'ever', 'every', \n",
    "    'for', 'from', 'get', 'got', 'had', 'has', 'have', 'he', \n",
    "    'her', 'hers', 'him', 'his', 'how', 'however', 'i', 'if', \n",
    "    'in', 'into', 'is', 'it', 'its', 'just', 'least', 'let', \n",
    "    'like', 'likely', 'may', 'me', 'might', 'most', 'must', \n",
    "    'my', 'neither', 'no', 'nor', 'not', 'of', 'off', 'often', \n",
    "    'on', 'only', 'or', 'other', 'our', 'own', 'rather', 'said', \n",
    "    'say', 'says', 'she', 'should', 'since', 'so', 'some', 'than', \n",
    "    'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', \n",
    "    'this', 'tis', 'to', 'too', 'twas', 'us', 'wants', 'was', \n",
    "    'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', \n",
    "    'whom', 'why', 'will', 'with', 'would', 'yet', 'you', 'your'}\n",
    "\n",
    "def simplified_lesk(word, sentence):\n",
    "    #--> Replace the pass statement with your implementation.\n",
    "    pass\n",
    "\n",
    "# Example 20.10 from the textbook. \n",
    "# Should return Synset('depository_financial_institution.n.01')\n",
    "# Double check whether it is correct using 2.3\n",
    "print(simplified_lesk(\n",
    "    'bank',\n",
    "    'the bank can guarantee deposits will eventually cover future \\\n",
    "     tuition costs because it invests in adjustable-rate mortage securities'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Original Lesk (2 pts)\n",
    "\n",
    "Implement the *original* Lesk algorithm to disambiguate words in the context of single sentences. Implement the algorithm as a function that accepts a word and its context (the sentence).\n",
    "\n",
    "**Hint:** Use your simplified Lesk function as a basis. You may find it handy to write a helper function that computes signatures from word senses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def original_lesk(word, sentence):\n",
    "    #--> Replace the pass statement with your implementation.\n",
    "    pass\n",
    "\n",
    "# Exercise 20.4 from the textbook (and an example from the original Lesk paper)\n",
    "print(original_lesk('time', 'time flies like an arrow'))  # Should return time.n.02\n",
    "print(original_lesk('flies', 'time flies like an arrow')) # Should return flies.n.01\n",
    "print(original_lesk('arrow', 'time flies like an arrow')) # Should return arrow.n.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Comparing the simplified and original Lesk algorithms (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(simplified_lesk('time', 'time flies like an arrow'))  # Should return time.n.01 \n",
    "print(simplified_lesk('flies', 'time flies like an arrow')) # Should return fly.v.08\n",
    "print(simplified_lesk('arrow', 'time flies like an arrow')) # Should return arrow.n.01\n",
    "# If the function returns other answers, check your simplified Lesk algorithm for mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Lesk variants disagree about every sense of the famous sentence 'Time flies like an arrow.' Examine their output. Do either of the algorithms disambiguate the sentence correctly? Which version do you think does a better job, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** *Double-click on this Markdown cell and replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
