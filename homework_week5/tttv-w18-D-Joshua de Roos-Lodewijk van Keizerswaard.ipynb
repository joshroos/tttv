{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taaltheorie en Taalverwerking · 2019 · Week 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN FOR YOUR GROUP, also name your file as: tttv-w18-<group>-<name1>-<name2>.ipynb\n",
    "\n",
    "# Group        : D\n",
    "# Name - UvaID : Joshua de Roos - 11242736\n",
    "# Name - UvaID : Lodewijk van Keizerswaard - 11054115\n",
    "# Date         : 07-05-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Order Logic\n",
    "\n",
    "For this assignment we will use another feature of NLTK, namely the ability to express first-order logic.\n",
    "Below you can find the demo function of this logic module, to gain some insight into how this system works.\n",
    "You will see examples of propositional logic, but also predicate logic, and the lambda calculus.\n",
    "\n",
    "### NLTK Semantic Logic demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Test reader====================\n",
      "john\n",
      "man(x)\n",
      "-man(x)\n",
      "(man(x) & tall(x) & walks(x))\n",
      "exists x.(man(x) & tall(x) & walks(x))\n",
      "\\x.man(x)\n",
      "\\x.man(x)(john)\n",
      "\\x y.sees(x,y)\n",
      "((\\x y.sees(x,y))(a))(b)\n",
      "(\\x.exists y.walks(x,y))(x)\n",
      "exists x.(x = y)\n",
      "exists x.(x = y)\n",
      "(P(x) & (x = y) & P(y))\n",
      "\\P Q.exists x.(P(x) & Q(x))\n",
      "(man(x) <-> tall(x))\n",
      "====================Test simplify====================\n",
      "\\x y.sees(x,y)\n",
      "\\y.sees(john,y)\n",
      "sees(john,mary)\n",
      "sees(john,mary)\n",
      "all x.(man(x) & exists y.walks(x,y))\n",
      "exists x.(dog(x) & bark(x))\n",
      "====================Test alpha conversion and binder expression equality====================\n",
      "exists x.P(x)\n",
      "exists z.P(z)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sem import logic\n",
    "from nltk.sem.logic import Expression, Variable\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.parse import FeatureChartParser\n",
    "from nltk import load_parser\n",
    "\n",
    "# http://www.nltk.org/_modules/nltk/sem/logic.html\n",
    "# http://www.nltk.org/book/ch10.html\n",
    "\n",
    "lexpr = Expression.fromstring\n",
    "print('='*20 + 'Test reader' + '='*20)\n",
    "print(lexpr(r'john'))\n",
    "print(lexpr(r'man(x)'))\n",
    "print(lexpr(r'-man(x)'))\n",
    "print(lexpr(r'(man(x) & tall(x) & walks(x))'))\n",
    "print(lexpr(r'exists x.(man(x) & tall(x) & walks(x))'))\n",
    "print(lexpr(r'\\x.man(x)'))\n",
    "print(lexpr(r'\\x.man(x)(john)'))\n",
    "print(lexpr(r'\\x y.sees(x,y)'))\n",
    "print(lexpr(r'\\x y.sees(x,y)(a,b)'))\n",
    "print(lexpr(r'(\\x.exists y.walks(x,y))(x)'))\n",
    "print(lexpr(r'exists x.x = y'))\n",
    "print(lexpr(r'exists x.(x = y)'))\n",
    "print(lexpr('P(x) & x=y & P(y)'))\n",
    "print(lexpr(r'\\P Q.exists x.(P(x) & Q(x))'))\n",
    "print(lexpr(r'man(x) <-> tall(x)'))\n",
    "\n",
    "print('='*20 + 'Test simplify' + '='*20)\n",
    "print(lexpr(r'\\x.\\y.sees(x,y)').simplify())\n",
    "print(lexpr(r'\\x.\\y.sees(x,y)(john)').simplify())\n",
    "print(lexpr(r'\\x.\\y.sees(x,y)(john)(mary)').simplify())\n",
    "print(lexpr(r'\\x.\\y.sees(x,y)(john, mary)').simplify())\n",
    "print(lexpr(r'all x.(man(x) & (\\x.exists y.walks(x,y))(x))').simplify())\n",
    "print(lexpr(r'(\\P.\\Q.exists x.(P(x) & Q(x)))(\\x.dog(x))(\\x.bark(x))').simplify())\n",
    "\n",
    "print('='*20 + 'Test alpha conversion and binder expression equality' + '='*20)\n",
    "e1 = lexpr('exists x.P(x)')\n",
    "print(e1)\n",
    "e2 = e1.alpha_convert(Variable('z'))\n",
    "print(e2)\n",
    "print(e1 == e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (11 pts total)\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td>Phrase structure rules</td>\n",
    "    <td>Lexicon</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>S $\\rightarrow$ NP VP</td>\n",
    "    <td>Det $\\rightarrow$ *a* | *every*</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>NP $\\rightarrow$ D N</td>\n",
    "    <td>N $\\rightarrow$ *restaurant* | *menu*</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>NP $\\rightarrow$ PN</td>\n",
    "    <td>PN $\\rightarrow$ *Albert*</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>VP $\\rightarrow$ V NP</td>\n",
    "    <td>V $\\rightarrow$ *has* | *opens*</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "In this exercise, you will implement the CFG with semantic attachments that you developed in Exercise 3 of the written homework as a Python CFG -- and then extend it. For convenience, the original CFG (without semantic attachments) appears above.\n",
    "\n",
    "### Question 1.1 (3 pts)\n",
    "\n",
    "Implement your CFG from Exercise 3(a) of the written homework as Python CFG -- including your semantic attachments! -- distinguishing between two types of rules: phrase-structure rules and lexical rules. \n",
    "\n",
    "#### Hint\n",
    "\n",
    "So that you don't despair while trying to discover how the NLTK syntax works, here is a simplified version of the simplified-grammar example that can be downloaded for NLTK (http://www.nltk.org/nltk_data/, under 'Grammars from NLTK Book'). From this example, you should be able to deduce how lambda calculus works in combination with the FeatureGrammar. For a more detailed explanation, see Chapter 10 of the NLTK Book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists x.(dog(x) & bite(x,angus))\n",
      "walk(cyril)\n",
      "all x.(dog(x) -> chase(x,irene))\n"
     ]
    }
   ],
   "source": [
    "example_rules = FeatureGrammar.fromstring(\"\"\"\n",
    "# DO NOT START WORKING IN THIS CELL. THIS IS AN EXAMPLE. THIS IS NOT THE ASSIGNMENT.\n",
    "\n",
    "\n",
    "# Simplified version of the simple-sem.fcfg file which can be downloaded for NLTK\n",
    "% start S\n",
    "############################\n",
    "# Phrase Structure Rules\n",
    "#############################\n",
    "\n",
    "S[SEM = <?subj(?vp)>] -> NP[SEM=?subj] VP[SEM=?vp]\n",
    "\n",
    "NP[SEM=<?det(?nom)> ] -> Det[SEM=?det]  Nom[SEM=?nom]\n",
    "NP[SEM=?np] -> PropN[SEM=?np]\n",
    "\n",
    "Nom[SEM=?nom] -> N[SEM=?nom]\n",
    "\n",
    "VP[SEM=?v] -> IV[SEM=?v]\n",
    "VP[SEM=<?v(?obj)>] -> TV[SEM=?v] NP[SEM=?obj]\n",
    "\n",
    "\n",
    "#############################\n",
    "# Lexical Rules\n",
    "#############################\n",
    "\n",
    "PropN[SEM=<\\P.P(angus)>] -> 'Angus'\n",
    "PropN[SEM=<\\P.P(cyril)>] -> 'Cyril'\n",
    "PropN[SEM=<\\P.P(irene)>] -> 'Irene'\n",
    "\n",
    "Det[SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
    "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some'\n",
    "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
    "\n",
    "######## backslash x bugs things out like mad in strings.. hence the \\y here\n",
    "N[SEM=<\\y.man(y)>] -> 'man'\n",
    "N[SEM=<\\y.girl(y)>] -> 'girl'\n",
    "N[SEM=<\\y.boy(y)>] -> 'boy'\n",
    "N[SEM=<\\y.bone(y)>] -> 'bone'\n",
    "N[SEM=<\\y.dog(y)>] -> 'dog'\n",
    "\n",
    "IV[SEM=<\\y.bark(y)>] -> 'barks'\n",
    "IV[SEM=<\\y.walk(y)>] -> 'walks'\n",
    "\n",
    "TV[SEM=<\\X x.X(\\y.chase(x,y))>] -> 'chases'\n",
    "TV[SEM=<\\X x.X(\\y.see(x,y))>] -> 'sees'\n",
    "TV[SEM=<\\X x.X(\\y.bite(x,y))>] -> 'bites'\n",
    "\n",
    "\"\"\")\n",
    "example_parser = FeatureChartParser(example_rules)\n",
    "\n",
    "example_sentences = [\n",
    "    'a dog bites Angus', \n",
    "    'Cyril walks', \n",
    "    'every dog chases Irene'\n",
    "]\n",
    "\n",
    "# If this prints nothing, it failed\n",
    "for sentence in example_sentences:\n",
    "    tokens = sentence.split()\n",
    "    for tree in example_parser.parse(tokens):\n",
    "        print(tree.label()['SEM'])\n",
    "\n",
    "# Output should be along the lines of:\n",
    "## exists x.(dog(x) & bite(x,angus))\n",
    "## walk(cyril)\n",
    "## all x.(dog(x) -> chase(x,irene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Cell\n",
    "\n",
    "Enter your implementation of your CFG with semantic attachments below. Be sure to implement the rules with the same names and structures you used in the written homework, *not* the names and structures from the NLTK Book example (e.g., **PN** and not **PropN**, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all x.(restaurant(x) -> exists z20.(menu(z20) & has(x,z20)))\n",
      "exists z21.(restaurant(z21) & opens(albert,z21))\n",
      "exists x.(restaurant(x) & exists z22.(menu(z22) & has(x,z22)))\n"
     ]
    }
   ],
   "source": [
    "rules = FeatureGrammar.fromstring(\"\"\"\n",
    "% start S\n",
    "############################\n",
    "# Phrase Structure Rules\n",
    "#############################\n",
    "\n",
    "S[SEM = <?subj(?vp)>] -> NP[SEM=?subj] VP[SEM=?vp]\n",
    "\n",
    "NP[SEM=<?det(?nom)> ] -> D[SEM=?det]  N[SEM=?nom]\n",
    "NP[SEM=?np] -> PN[SEM=?np]\n",
    "\n",
    "VP[SEM=<?v(?obj)>] -> V[SEM=?v] NP[SEM=?obj]\n",
    "\n",
    "#############################\n",
    "# Lexical Rules\n",
    "#############################\n",
    "\n",
    "N[SEM=<\\y.restaurant(y)>] -> 'restaurant'\n",
    "N[SEM=<\\y.menu(y)>] -> 'menu'\n",
    "\n",
    "PN[SEM=<\\P.P(albert)>] -> 'Albert'\n",
    "\n",
    "D[SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
    "D[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
    "\n",
    "\n",
    "V[SEM=<\\X x.X(\\y.has(x,y))>] -> 'has'\n",
    "V[SEM=<\\X x.X(\\y.opens(x,y))>] -> 'opens'\n",
    "\n",
    "\"\"\")\n",
    "parser = FeatureChartParser(rules)\n",
    "\n",
    "sentences = [\n",
    "    'every restaurant has a menu', \n",
    "    'Albert opens a restaurant', \n",
    "    'a restaurant has a menu',\n",
    "]\n",
    "\n",
    "# If this prints nothing, it failed\n",
    "for sentence in sentences:\n",
    "    tokens = sentence.split()\n",
    "    for tree in parser.parse(tokens):\n",
    "        print(tree.label()['SEM'])\n",
    "\n",
    "# Output should be similar, although variable names such as z1, z2, z3 might differ per line\n",
    "## all x.(restaurant(x) -> exists z2.(menu(z2) & has(x,z2)))\n",
    "## exists z3.(restaurant(z3) & opens(albert,z3))\n",
    "## exists x.(restaurant(x) & exists z4.(menu(z4) & has(x,z4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1.2 (8 pts)\n",
    "\n",
    "Make the following modifications to your implemented grammar. Start by copying the rules you wrote above into this new grammar.\n",
    "\n",
    "Then **substitute the the following three rules** for **NP $\\rightarrow$ D N** in order to allow for pre-nominal adjectives. (You have to determine the semantic syntax yourself, of course.)\n",
    "\n",
    "* NP $\\rightarrow$ D Nom\n",
    "* Nom $\\rightarrow$ A Nom\n",
    "* Nom $\\rightarrow$ N\n",
    "\n",
    "Also **add a few adjectives** to the lexicon:\n",
    "\n",
    "* A $\\rightarrow$ 'vegetarian'\n",
    "* A $\\rightarrow$ 'new'\n",
    "* A $\\rightarrow$ 'special'\n",
    "\n",
    "The resulting grammar should be able to parse such sentences as:  \n",
    "* 'Albert opens a new restaurant' \n",
    "* 'Every vegetarian restaurant has a new menu' \n",
    "* 'Albert has a new vegetarian menu' \n",
    "\n",
    "and produce the correct logical forms for them. If you have done everything right, your semantic grammar will be able to compute logical forms like the following: \n",
    "\n",
    "    'Albert opens a new restaurant'\n",
    "    exists z5.(restaurant(z5) & new(z5) & opens(albert,z5))\n",
    "\n",
    "#### Hint\n",
    "\n",
    "Think about what is required to compositionally build the semantic representation of sentences with pre-nominal adjectives: which $\\lambda$-expression should be assigned to the lexical entry of an adjective? To translate sentences with NPs that contain adjectives we use conjunction. For instance, as you see above the sentence  'Albert opens a new restaurant' is translated as $\\exists x [ (Restaurant(x) \\wedge New(x)) \\wedge Opened(a,x)]$. The part $(Restaurant(x) \\wedge New(x))$ in this formula must be built up with the syntactic rule ${\\it Nom} \\rightarrow A \\ {\\it Nom}$. Hence, in the lexicon you need to give a $\\lambda$-expression for adjectives that makes clear which bits in this part of a formula are contributed by the adjective itself and which bits are abstracted away (and will then be contributed by the noun, thanks to rule $Nom \\rightarrow A \\ Nom$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all x.(restaurant(x) -> exists z23.(menu(z23) & vegetarian(z23) & has(x,z23)))\n",
      "all x.(restaurant(x) -> exists z24.(menu(z24) & new(z24) & has(x,z24)))\n",
      "exists z25.(restaurant(z25) & new(z25) & opens(albert,z25))\n",
      "exists x.(restaurant(x) & exists z26.(menu(z26) & has(x,z26)))\n",
      "exists x.(restaurant(x) & exists z27.(menu(z27) & vegetarian(z27) & new(z27) & has(x,z27)))\n",
      "exists z28.(restaurant(z28) & vegetarian(z28) & special(z28) & new(z28) & opens(albert,z28))\n"
     ]
    }
   ],
   "source": [
    "rules2 = FeatureGrammar.fromstring(\"\"\"\n",
    "% start S\n",
    "############################\n",
    "# Phrase Structure Rules\n",
    "#############################\n",
    "\n",
    "S[SEM = <?subj(?vp)>] -> NP[SEM=?subj] VP[SEM=?vp]\n",
    "\n",
    "NP[SEM=<?det(?nom)> ] -> D[SEM=?det]  Nom[SEM=?nom]\n",
    "NP[SEM=?np] -> PN[SEM=?np]\n",
    "\n",
    "Nom[SEM=<?a(?nom)>] -> A[SEM=?a] Nom[SEM=?nom]\n",
    "Nom[SEM=?n] -> N[SEM=?n]\n",
    "\n",
    "VP[SEM=<?v(?obj)>] -> V[SEM=?v] NP[SEM=?obj]\n",
    "\n",
    "#############################\n",
    "# Lexical Rules\n",
    "#############################\n",
    "\n",
    "N[SEM=<\\y.restaurant(y)>] -> 'restaurant'\n",
    "N[SEM=<\\y.menu(y)>] -> 'menu'\n",
    "\n",
    "PN[SEM=<\\P.P(albert)>] -> 'Albert'\n",
    "\n",
    "D[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
    "D[SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
    "\n",
    "V[SEM=<\\X x.X(\\y.has(x,y))>] -> 'has'\n",
    "V[SEM=<\\X x.X(\\y.opens(x,y))>] -> 'opens'\n",
    "\n",
    "A[SEM=<\\P x.(P(x) & vegetarian(x))>] -> 'vegetarian'\n",
    "A[SEM=<\\P x.(P(x) & new(x))>] -> 'new'\n",
    "A[SEM=<\\P x.(P(x) & special(x))>] -> 'special'\n",
    "\"\"\")\n",
    "parser = FeatureChartParser(rules2)\n",
    "\n",
    "sentences2 = [\n",
    "    'every restaurant has a vegetarian menu', \n",
    "    'every restaurant has a new menu', \n",
    "    'Albert opens a new restaurant', \n",
    "    'a restaurant has a menu',\n",
    "    'a restaurant has a new vegetarian menu',\n",
    "    'Albert opens a new special vegetarian restaurant',\n",
    "]\n",
    "\n",
    "# If this prints nothing, it failed\n",
    "for sentence in sentences2:\n",
    "    tokens = sentence.split()\n",
    "    for tree in parser.parse(tokens):\n",
    "        print(tree.label()['SEM'])\n",
    "\n",
    "# Output should be similar, although variable names such as z1, z2, z3 might differ per line\n",
    "## all x.(restaurant(x) -> exists z56.(menu(z56) & vegetarian(z56) & has(x,z56)))\n",
    "## all x.(restaurant(x) -> exists z57.(menu(z57) & new(z57) & has(x,z57)))\n",
    "## exists z58.(restaurant(z58) & new(z58) & opens(albert,z58))\n",
    "## exists x.(restaurant(x) & exists z59.(menu(z59) & has(x,z59)))\n",
    "## exists x.(restaurant(x) & exists z60.(menu(z60) & vegetarian(z60) & new(z60) & has(x,z60))\n",
    "## exists z71.(restaurant(z71) & vegetarian(z71) & special(z71) & new(z71) & opens(albert,z71))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
