{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taaltheorie en Taalverwerking · 2019 · Week 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN FOR YOUR GROUP, also name your file as: tttv-w16-<group>-<name1>-<name2>.ipynb\n",
    "\n",
    "# Group        : D\n",
    "# Name - UvaID : Joshua de Roos - 11242736\n",
    "# Name - UvaID : Lodewijk van Keizerswaard - 11054115\n",
    "# Date         : 23-04-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.parse import RecursiveDescentParser, FeatureEarleyChartParser\n",
    "\n",
    "# Function that works for multiple types of parsers (You are free to use something else if you want.)\n",
    "def check_sentence(parser, sentence):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Checking if provided sentence matches the grammar:\")\n",
    "    print(sentence)\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.split()\n",
    "    tree_found = False\n",
    "    results = parser.parse(sentence)\n",
    "    for tree in results:\n",
    "        tree_found = True\n",
    "        print(tree)\n",
    "    if not tree_found:\n",
    "        print(sentence, \"Does not match the provided grammar.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    return tree_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this set of exercises is to implement the shift-reduce algorithm for bottom-up parsing. We will use the following grammar for most of our examples, which is a slightly modified version of the grammar we used in the exercises last week:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td>Phrase structure rules</td>\n",
    "    <td>Lexicon</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>S $\\rightarrow$ NP VP</td>\n",
    "    <td>Det $\\rightarrow$ *the*</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>NP $\\rightarrow$ Det N</td>\n",
    "    <td>N $\\rightarrow$ *journalist* | *detective*</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>VP $\\rightarrow$ V NP</td>\n",
    "    <td>V $\\rightarrow$ *interviews* | *photographs*</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>V $\\rightarrow$ V C V</td>\n",
    "    <td>C $\\rightarrow$ *and* | *or*</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "This grammar allows sentences such as *the detective interviews the journalist* as well as sentences such as *the journalist interviews and photographs the detective*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (4 pts)\n",
    "\n",
    "Encode the above grammar as a CFG named **cfg_1**, using NLTK. Then try to parse the following sentence: *The detective interviews and photographs the journalist.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the declaration of cfg_1\n",
    "cfg_1 = CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  NP -> Det N\n",
    "  VP -> V NP\n",
    "  V -> V C V\n",
    "  Det -> 'the'\n",
    "  N -> 'journalist' | 'detective'\n",
    "  V -> 'interviews' | 'photographs'\n",
    "  C -> 'and' | 'or'\n",
    "\"\"\")\n",
    "\n",
    "# Use RecursiveDescentParser for this example.\n",
    "cfg_1_parser = RecursiveDescentParser(cfg_1)\n",
    "# The following inputs should produce the corresponding results\n",
    "check_sentence(cfg_1_parser, 'the detective interviews and photographs the journalist') # RecursionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, this does not work for the *RecursiveDescentParser*.\n",
    "\n",
    "If this does work, then try to parse the string *the detective interviews*, which should fail, and continue with the exercise. \n",
    "Trace the execution of the query. Document and explain what happens by making reference to the properties of the grammar rules and the parsing strategy employed by the CFG (_Hint_: The error traces have comments, which could help you. Try scrolling through them and try if you can see a pattern). Be thorough in your answer.\n",
    "\n",
    "**Answers:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Recursive Descent parser is a top-down, depth-first parser that works from left to right. When parsing the sentence above the algorithm eventually ends up at the rule `V -> V C V`. Since this is a left-recursive rule, the algorithm will keep expanding `V` to `V C V`. This causes an infinite loop and is the reason that the RecursiveDescentParser can not parse this sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would a top-down breadth-first parsing strategy have the same problem as the *RecursiveDescentParser* parser? Explain why.\n",
    "\n",
    "**Answers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No, a breadth-first parser would not have this problem. This parser would consider every possible tree at each level before expanding to the next level. So, at some point it would find the correct parsing tree for the sentence and not go in to an infinite loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (2 pts)\n",
    "Encode the same grammar using the following notation. Each rule is represented by a fact of the form **rule\\[Left\\] = Right**, where **Left** stands for an atom representing the lefthand side of a rule, and **Right** stands for the list of terminal and nonterminal symbols on the righthand side of the rule. For the sake of keeping our sanity in Python we will not store the rules individually, but we store them in a dictionary where **Left** forms the key, and **Right** is stored in a list for each **Left**. For example, the first and the last rule of our grammar would be added as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['np', 'vp']]\n",
      "[['det', 'n']]\n",
      "[['v', 'np']]\n",
      "[['v', 'c', 'v'], ['interviews'], ['photographs']]\n",
      "[['the']]\n",
      "[['journalist'], ['detective']]\n",
      "[['or'], ['and']]\n"
     ]
    }
   ],
   "source": [
    "def add_rule(rules, left, right):\n",
    "    # If the key does not already exist, initialize it with a list.\n",
    "    if left not in rules:\n",
    "        rules[left] = []\n",
    "    rules[left].append(right)\n",
    "rules = dict()\n",
    "add_rule(rules, 's', ['np', 'vp'])\n",
    "add_rule(rules, 'np', ['det', 'n'])\n",
    "add_rule(rules, 'vp', ['v', 'np'])\n",
    "add_rule(rules, 'v', ['v', 'c', 'v'])\n",
    "add_rule(rules, 'det', ['the'])\n",
    "add_rule(rules, 'n', ['journalist'])\n",
    "add_rule(rules, 'n', ['detective'])\n",
    "add_rule(rules, 'v', ['interviews'])\n",
    "add_rule(rules, 'v', ['photographs'])\n",
    "add_rule(rules, 'c', ['or'])\n",
    "add_rule(rules, 'c', ['and'])\n",
    "\n",
    "for rule in rules:\n",
    "    print(rules[rule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (6 pts)\n",
    "\n",
    "Now implement the shift-reduce algorithm as a function **shift_reduce(rules, atoms_list, goal)**. The first argument holds the rules of the CFG, the second arguments represents the string of words to be parsed (a list of atoms), and the third argument represents the constituent(s) as which those words should be parsed, i.e., the parsing goal (also a list of atoms, possibly just a single atom). \n",
    "\n",
    "For example, this indicates that this input string of words can be parsed as a sentence: \n",
    "\n",
    "    shift_reduce(rules, 'the journalist interviews and interviews and interviews the detective'.split(), ['s']) # True\n",
    "\n",
    "This indicates that this string of words cannot be parsed as the two constituents NP and VP:\n",
    "\n",
    "    shift_reduce(rules, 'the journalist interviews'.split(), ['np', 'vp']) # False\n",
    "    \n",
    "Proceed as follows:\n",
    "1. Start with an empty memory stack (mem_list)\n",
    "2. Apply the shift operation:  remove the first word from the current sentence and shift it onto the memory stack (i.e., append it to the end of the list representing the memory component).\n",
    "3. Try to reduce the memory stack as much as you can: find a rule the righthand side of which matches the last few elements on the memory stack, remove them from the memory, and instead include the lefthand side of the chosen rule at the same position in the memory component.\n",
    "4. If you cannot reduce any further, shift again and so on.\n",
    "\n",
    "When you can no longer shift and reduce, check whether the current memory component is identical with the parsing goal (goal), then you are done.\n",
    "\n",
    "Tip: it can help to create a separate helper function for the reduce step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "False\n",
      "the\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## Helper Functions (if needed)\n",
    "def reduce_atoms(rules, atoms):\n",
    "    for rule in rules:\n",
    "        for expansion in rules[rule]:\n",
    "            if atoms == expansion:\n",
    "                return rule\n",
    "    return None\n",
    "        \n",
    "\n",
    "## Actual Function\n",
    "def shift_reduce(rules, atoms_list, goal):\n",
    "    mem_list = []\n",
    "    \n",
    "    atom = atoms_list.pop(0)\n",
    "    mem_list.append(atom)\n",
    "    \n",
    "    return False\n",
    "\n",
    "print(shift_reduce(rules, 'the journalist interviews and interviews and interviews the detective'.split(), ['s'])) #True\n",
    "print(shift_reduce(rules, 'the journalist interviews'.split(), ['np', 'vp'])) # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document that your function **shift_reduce(rules, atoms_list, goal)** (leaving the mem\\_list empty) works as intended by showing the output for three (interesting) queries (that need to be different from the queries shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_reduce(rules, 'interesting sentence 1', [])\n",
    "shift_reduce(rules, 'interesting sentence 2', [])\n",
    "shift_reduce(rules, 'interesting sentence 3', [])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
